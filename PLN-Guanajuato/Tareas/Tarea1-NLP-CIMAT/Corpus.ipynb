{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de un corpus\n",
    "\n",
    "La realización del corpus se hará sobre las conferencias de prensa (\"mañaneras\") de la presidenta Claudia Sheinbaum y del ex-presidente Andres Manuel López Obrador.  \n",
    "\n",
    "**Fuentes**\n",
    "* Para las conferencias de la presidenta: https://www.gob.mx/presidencia/es/archivo/articulos?fechaFin=2025-01-23+00%3A00%3A00&fechaInicio=2024-11-01+00%3A00%3A00&idiom=es&order=DESC&q=Conferencia+de+prensa&section=articulos&site=presidencia&utf8=%E2%9C%93&page=1\n",
    "\n",
    "* Para las conferencias del ex-presidente: https://amlo.presidente.gob.mx/sala-de-prensa/transcripciones/page/1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importamos primero las principales librerías que utilizaremos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import glob\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos carpetas en caso de no existir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = [\"clean_estenograficas\",\n",
    "            \"estenograficas\",\n",
    "            \"paginas\",\n",
    "            \"raw_discursos\",\n",
    "            \"text_discursos\"]\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    if not os.path.isdir(f\".\\\\{carpeta}\\\\\"):\n",
    "        os.mkdir(f\".\\\\{carpeta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos una función para verificar que un archivo no exista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_existe(path):\n",
    "    return not os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para la presidenta Claudia Sheinbaum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bajamos todas las páginas del archivo de mañaneras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pagina_i = r\"https://www.gob.mx/presidencia/es/archivo/articulos?fechaFin=2025-01-23\" + \\\n",
    "    r\"+00%3A00%3A00&fechaInicio=2024-11-01+00%3A00%3A00&idiom=es&order=DESC\"+\\\n",
    "        r\"&q=Conferencia+de+prensa&section=articulos&site=presidencia&utf8=%E2%9C%93&page=\"\n",
    "\n",
    "# Al 23 de Enero de 2025\n",
    "num_paginas = 6\n",
    "\n",
    "for i in range(1,num_paginas+1):\n",
    "    url_pagina = url_pagina_i + str(i)\n",
    "    nombre = 'paginas\\\\shein_pagina'+str(i)+'.txt'\n",
    "    if no_existe(nombre):\n",
    "        wget.download(url_pagina,nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Obtenemos las mañaneras en cada página y las descargamos**\n",
    "El resultado se guarda en la carpeta `raw_discursos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_conf = []\n",
    "\n",
    "# Expresion regular para encontrar links a las versiones estenográficas\n",
    "# dentro de cada página.\n",
    "patron = r'href=\"([^\"]*version-estenografica[^\"]*)\"'\n",
    "\n",
    "for f_pagina in glob.glob(\"./paginas/shein*.txt\"):\n",
    "    urls_conf += [\n",
    "        path\n",
    "        for path in re.findall(\n",
    "            patron, open(f_pagina, \"r\", encoding=\"utf-8\").read()\n",
    "        )\n",
    "        if \"estenografica\" in path\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Mañaneras:  52\n",
      "/presidencia/es/articulos/version-estenografica-conferencia-de-prensa-de-la-presidenta-claudia-sheinbaum-pardo-del-23-de-enero-de-2025?idiom=es\n"
     ]
    }
   ],
   "source": [
    "print(\"No. Mañaneras: \", len(urls_conf))\n",
    "print(urls_conf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in urls_conf:\n",
    "    nombre = \"./raw_discursos/\"+path.split(\"/\")[-1][:-10]+\".txt\"\n",
    "    if no_existe(nombre):\n",
    "        f = wget.download(url = \"https://www.gob.mx\"+path, out=nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ahora limpiamos los html para obtener el puro texto de las páginas.**\n",
    "El resultado se guarda en la carpeta `text_discursos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_pagina in glob.glob(\".\\\\raw_discursos\\\\*.txt\"):\n",
    "    soup = BeautifulSoup(open(f_pagina, \"r\", encoding=\"utf-8\").read(), \"html.parser\")\n",
    "    filename = \".\\\\text_discursos\\\\\"+f_pagina.replace(f\".\\\\raw_discursos\\\\\",\"\")\n",
    "    if no_existe(filename):\n",
    "        open(filename, \"w\", encoding=\"utf-8\").write(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Renombramos con la fecha**: \n",
    "* Al inicio de cada texto viene la fecha en formato ``\"dd de \\<mes\\> de yyyy\"``.  \n",
    "    - El resultado se guarda en la carpeta `estenograficas`.\n",
    "\n",
    "Le pondré que inicie con ``\"|\"`` para que encuentre solo una ocurrencia por archivo (Linea 196 de cada texto).  \n",
    "Podría también, para cada búsqueda, simplemente seleccionar el primer elemento que encuentre, no sé cuál sea una mejor práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_re = r'\\| \\d{1,2} de [a-z]+ de \\d{4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = {\n",
    "    \"enero\" : 1,\n",
    "    \"febrero\" : 2,\n",
    "    \"marzo\" : 3,\n",
    "    \"abril\" : 4,\n",
    "    \"mayo\" : 5,\n",
    "    \"junio\" : 6,\n",
    "    \"julio\" : 7,\n",
    "    \"agosto\" : 8,\n",
    "    \"septiembre\" : 9,\n",
    "    \"octubre\" : 10,\n",
    "    \"noviembre\" : 11,\n",
    "    \"diciembre\" : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10 de diciembre de 2024'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifico que encuentre 51 fechas, correspondiente a 51 mañaneras.\n",
    "fecha = []\n",
    "\n",
    "for f_pagina in glob.glob(\".\\\\text_discursos\\\\*.txt\"):\n",
    "    fecha += re.findall(fecha_re, open(f_pagina, \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "print(len(fecha))\n",
    "print(len(set(fecha)))\n",
    "fecha[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos todos los archivos y los pasamos a la carpeta \"estenograficas\".\n",
    "for f_pagina in glob.glob(\".\\\\text_discursos\\\\*.txt\"):\n",
    "    # Extraer la fecha del archivo\n",
    "    fecha = re.findall(fecha_re, open(f_pagina, \"r\", encoding=\"utf-8\").read())[0][2:]\n",
    "    fecha = fecha.split(\" de \")\n",
    "    fecha = datetime.date(int(fecha[2]), meses[fecha[1]], int(fecha[0]))\n",
    "    \n",
    "    # Nuevo nombre del archivo\n",
    "    new_str = fecha.strftime(\"%Y-%m-%d\")\n",
    "    new_name = \".\\\\estenograficas\\\\\" + new_str + \".txt\"\n",
    "        \n",
    "    # Copiar el archivo\n",
    "    if no_existe(new_name):\n",
    "        shutil.copy(f_pagina, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Limpiar textos:** \n",
    "* Hacer que contenga únicamente el texto relevante.\n",
    "    - Se guardan en la carpeta `clean_estenograficas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicadores de inicio y final de la conferencia.\n",
    "\n",
    "re_inicio = r\"CLAUDIA SHEINBAUM PARDO:\" # Siempre inician con la presidenta hablando.\n",
    "\n",
    "re_final1 = r\"—000—\"\n",
    "re_final2 = r\"---000---\"\n",
    "re_final3 = r\"---00---\" # Terminan de 3 formas, está extraño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo in glob.glob(\".\\\\estenograficas\\\\*.txt\"):\n",
    "    actual_archivo = open(archivo, \"r\", encoding=\"utf-8\")\n",
    "    lineas = actual_archivo.readlines()\n",
    "    nuevo_nombre = archivo.replace(\"estenograficas\",\"clean_estenograficas\")\n",
    "    nuevo_archivo = open(nuevo_nombre, \"w\")\n",
    "    \n",
    "    inicio = False\n",
    "    for linea in lineas:\n",
    "        # Definimos el inicio\n",
    "        if (bool(re.search(re_inicio,linea))):\n",
    "            inicio = True\n",
    "        if not inicio:\n",
    "            continue\n",
    "        \n",
    "        # Definimos el final\n",
    "        if (bool(re.search(re_final1, linea)) or\n",
    "            bool(re.search(re_final2, linea)) or\n",
    "            bool(re.search(re_final3, linea))):\n",
    "            break\n",
    "        \n",
    "        # En caso de que ya sea el cuerpo del texto.\n",
    "        nuevo_archivo.write(linea)\n",
    "    nuevo_archivo.close()\n",
    "    actual_archivo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borrar archivos ya innecesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminar el contenido de las carpetas `raw_discursos`, `paginas` y `text_discursos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = [\"raw_discursos\",\n",
    "            \"paginas\",\n",
    "            \"text_discursos\",\n",
    "            \"estenograficas\"]\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    for archivo in glob.glob(f\".\\\\{carpeta}\\\\*.txt\"):\n",
    "        os.remove(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para el ex-presidente López Obrador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pagina_i = r\"https://amlo.presidente.gob.mx/sala-de-prensa/transcripciones/page/\"\n",
    "\n",
    "num_paginas = 287\n",
    "\n",
    "for i in range(1,num_paginas+1):\n",
    "    url_pagina = url_pagina_i + str(i)\n",
    "    nombre = './paginas/amlo_pagina'+str(i)+'.txt'\n",
    "    if no_existe(nombre):\n",
    "        wget.download(url_pagina,nombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_conf = []\n",
    "\n",
    "# Expresion regular para encontrar links a las versiones estenográficas\n",
    "# dentro de cada página.\n",
    "patron = r'href=\"([^\"]*conferencia-de-prensa[^\"]*)\"'\n",
    "\n",
    "for f_pagina in glob.glob(\"./paginas/amlo*.txt\"):\n",
    "    urls_conf += [\n",
    "        path\n",
    "        for path in re.findall(\n",
    "            patron, open(f_pagina, \"r\", encoding=\"utf-8\").read()\n",
    "        )\n",
    "        if \"estenografica\" in path\n",
    "    ]\n",
    "    \n",
    "urls_conf = [url for url in urls_conf if not url.endswith(\"#comments\")]\n",
    "urls_conf = sorted(list(set(urls_conf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Mañaneras:  1370\n",
      "01-02-22-version-estenografica-de-la-conferencia-de-prensa-matutina-del-presidente-andres-manuel-lopez-obrador\n",
      "https://amlo.presidente.gob.mx/01-02-22-version-estenografica-de-la-conferencia-de-prensa-matutina-del-presidente-andres-manuel-lopez-obrador/\n"
     ]
    }
   ],
   "source": [
    "print(\"No. Mañaneras: \", len(urls_conf))\n",
    "print(urls_conf[0].split(\"/\")[-2])\n",
    "print(urls_conf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in urls_conf:\n",
    "    nombre = path.split(\"/\")[-2]\n",
    "    nombre_archivo = \"./raw_discursos/\"+nombre+\".txt\"\n",
    "    if no_existe(nombre_archivo):\n",
    "        f = wget.download(url = path, out=nombre_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_pagina in glob.glob(\".\\\\raw_discursos\\\\*.txt\"):\n",
    "    soup = BeautifulSoup(open(f_pagina, \"r\", encoding=\"utf-8\").read(), \"html.parser\")\n",
    "    filename = \".\\\\text_discursos\\\\\"+f_pagina.replace(f\".\\\\raw_discursos\\\\\",\"\")\n",
    "    if no_existe(filename):\n",
    "        open(filename, \"w\", encoding=\"utf-8\").write(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_re = r'[a-z] \\d{2}.\\d{2}.\\d{2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\n",
      "1359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['01.02.22', '01.02.23', '01.03.21']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifico que encuentre 1370 fechas, correspondiente a 1370 mañaneras.\n",
    "fechas = []\n",
    "\n",
    "for f_pagina in glob.glob(\".\\\\text_discursos\\\\*.txt\"):\n",
    "    fechas_en_archivo = re.findall(fecha_re, open(f_pagina, \"r\", encoding=\"utf-8\").read())\n",
    "    \n",
    "    if not fechas_en_archivo:\n",
    "        # Si no encuentra fechas, elimina el documento.\n",
    "        print(\"No coincidio en:\", f_pagina)\n",
    "        os.remove(f_pagina)\n",
    "        continue\n",
    "    \n",
    "    if fechas_en_archivo[0] in fechas:\n",
    "        # Simplemente quitaremos mañaneras con segunda parte, etc.\n",
    "        # Son pocas (8).\n",
    "        print(\"Fecha repetida: \",fechas_en_archivo[0], f_pagina)\n",
    "        os.remove(f_pagina)\n",
    "        continue\n",
    "\n",
    "    fechas.append(fechas_en_archivo[0]) \n",
    "    \n",
    "\n",
    "print(len(fechas))\n",
    "print(len(set(fechas)))\n",
    "fechas = [fecha[2:] for fecha in fechas]\n",
    "fechas[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos todos los archivos y los pasamos a la carpeta \"estenograficas\".\n",
    "for f_pagina in glob.glob(\".\\\\text_discursos\\\\*.txt\"):\n",
    "    \n",
    "    # Extraer la fecha del archivo\n",
    "    fecha = re.findall(fecha_re, open(f_pagina, \"r\", encoding=\"utf-8\").read())[0][2:]\n",
    "    fecha = fecha.split(\".\")\n",
    "    fecha = datetime.date(2000 + int(fecha[2]), int(fecha[1]), int(fecha[0]))\n",
    "    \n",
    "    # Nuevo nombre del archivo\n",
    "    new_str = fecha.strftime(\"%Y-%m-%d\")\n",
    "    new_name = \".\\\\estenograficas\\\\\" + new_str + \".txt\"\n",
    "        \n",
    "    # Copiar el archivo\n",
    "    if no_existe(new_name):\n",
    "        shutil.copy(f_pagina, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicadores de inicio y final de la conferencia.\n",
    "\n",
    "re_inicio = r\"ANDRÉS MANUEL LÓPEZ OBRADOR:\" # Siempre inician con la presidenta hablando.\n",
    "\n",
    "# Terminan de mil formas, no me voy a esforzar en esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo in glob.glob(\".\\\\estenograficas\\\\*.txt\"):\n",
    "    actual_archivo = open(archivo, \"r\", encoding=\"utf-8\")\n",
    "    lineas = actual_archivo.readlines()\n",
    "    nuevo_nombre = archivo.replace(\"estenograficas\",\"clean_estenograficas\")\n",
    "    nuevo_archivo = open(nuevo_nombre, \"w\")\n",
    "    \n",
    "    inicio = False\n",
    "    for linea in lineas:\n",
    "        # Definimos el inicio\n",
    "        if (bool(re.search(re_inicio,linea))):\n",
    "            inicio = True\n",
    "        if not inicio:\n",
    "            continue\n",
    "        \n",
    "        # En caso de que ya sea el cuerpo del texto.\n",
    "        nuevo_archivo.write(linea)\n",
    "    nuevo_archivo.close()\n",
    "    actual_archivo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borrar archivos ya innecesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminar el contenido de las carpetas `raw_discursos`, `paginas` y `text_discursos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = [\"raw_discursos\",\n",
    "            \"paginas\",\n",
    "            \"text_discursos\",\n",
    "            \"estenograficas\"]\n",
    "\n",
    "for carpeta in carpetas:\n",
    "    for archivo in glob.glob(f\".\\\\{carpeta}\\\\*.txt\"):\n",
    "        os.remove(archivo)\n",
    "    os.rmdir(f\".\\\\{carpeta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el archivo para corpus\n",
    "corpus = \"\"\n",
    "for archivo in glob.glob(\".\\\\clean_estenograficas\\\\*.txt\"):\n",
    "    corpus += open(archivo, \"r\", encoding=\"utf-8\").read() + \"\\n\"\n",
    "\n",
    "with open(\".\\\\corpus.txt\", \"w\", encoding=\"utf-8\") as archivo:\n",
    "    archivo.write(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
