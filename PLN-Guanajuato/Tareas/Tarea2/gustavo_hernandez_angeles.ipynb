{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 - NLP CIMAT: Minería de Texto Básica\n",
    "## Por: Gustavo Hernández Angeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación (Lectura de corpus, tokenización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leyendo corpus\n",
    "* Utilizaré parte del código visto en la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus, path_labels):\n",
    "    tr_txt = []\n",
    "    tr_y = []\n",
    "\n",
    "    with open(path_corpus, \"r\", encoding=\"utf-8-sig\") as f_corpus, open(path_labels, \"r\", encoding=\"utf-8-sig\") as f_truth:\n",
    "        for twitt in f_corpus:\n",
    "            tr_txt += [twitt.strip()]\n",
    "        for label in f_truth:\n",
    "            tr_y += [label.strip()]\n",
    "\n",
    "    return tr_txt, tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, tr_y = get_texts_from_file(\"./data/mex_train.txt\", \"./data/mex_train_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt, val_y = get_texts_from_file(\"./data/mex_val.txt\", \"./data/mex_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tokenizacion de Corpus  \n",
    "Haré que solo lea las palabras y quitaré los stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-ZáéíóúñÁÉÍÓÚÑ]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 12161\n"
     ]
    }
   ],
   "source": [
    "stopwords_espanol = stopwords.words(\"spanish\")\n",
    "corpus_palabras = []\n",
    "for doc in tr_txt:\n",
    "    text = tokenizer.tokenize(doc)\n",
    "    corpus_palabras += [w.lower() for w in text if w.lower() not in stopwords_espanol]\n",
    "\n",
    "fdist = nltk.FreqDist(corpus_palabras)\n",
    "print(f\"Tamaño del vocabulario: {len(fdist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se hace un filtrado por frecuencia, al hacer esto, reducimos el tamaño del vocabulario de 14268 a 4683  \n",
    "Se escoge un umbral de 1, valor mayor reduce más el vocabulario.  \n",
    "Con 2 -> el tamaño de V es 2749  \n",
    "Con 3 -> el tamaño de V es 1973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 4281\n"
     ]
    }
   ],
   "source": [
    "K_umbral = 1\n",
    "V = [(fdist[key], key) for key in fdist if fdist[key] > K_umbral] # Más de una ocurrencia\n",
    "V.sort()\n",
    "V.reverse()\n",
    "print(f\"Tamaño del vocabulario: {len(V)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for freq, word in V:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bolsas de Palabras, Bigramas y Emociones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Evalúe BOW con pesado binario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Definimos una función para realizar el BOW con peso binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binario_bow(tr_txt, V, dict_indices):\n",
    "    BOW = np.zeros(shape=(len(tr_txt), len(V)), dtype=int)\n",
    "    \n",
    "    cont_doc = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        \n",
    "        for word in fdist_doc:\n",
    "            # Se elige ignorar si un término no está en el vocab.\n",
    "            if word not in dict_indices:\n",
    "                continue\n",
    "            BOW[cont_doc, dict_indices[word]] = 1\n",
    "            \n",
    "        cont_doc += 1\n",
    "    \n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Definimos una función para evaluar el SVM dados las BOW de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_bow(BOW_train, BOW_test, val_y):\n",
    "    # Parámetro de complejidad del SVM, se proponen estos\n",
    "    # y se recorrerán con GridSearch\n",
    "    parameters = {\"C\": [.05, .12, .25, .5, 1, 2, 4]}\n",
    "    # Tratar de penalizar con base a la proporción de ejemplos\n",
    "    # en cada clase\n",
    "    svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "    grid = GridSearchCV(estimator=svr, param_grid=parameters,\n",
    "                        n_jobs=6, scoring=\"f1_macro\", cv=5)\n",
    "    grid.fit(BOW_train, tr_y)\n",
    "    y_pred = grid.predict(BOW_test)\n",
    "\n",
    "    print(confusion_matrix(val_y, y_pred))\n",
    "    print(metrics.classification_report(val_y, y_pred))\n",
    "    print(f\"F1-score: {f1_score(val_y, y_pred, pos_label='1'):.4f}\")\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluamos con pesado binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[363  55]\n",
      " [ 50 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       418\n",
      "           1       0.68      0.70      0.69       169\n",
      "\n",
      "    accuracy                           0.82       587\n",
      "   macro avg       0.78      0.79      0.78       587\n",
      "weighted avg       0.82      0.82      0.82       587\n",
      "\n",
      "F1-score: 0.6939\n"
     ]
    }
   ],
   "source": [
    "BOW_train = binario_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = binario_bow(val_txt, V, dict_indices)\n",
    "svm_binario = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evalúe BOW con pesado frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos BOW con esquema de peso de frecuencia.\n",
    "def frecuencia_bow(tr_txt, V, dict_indices):\n",
    "    BOW = np.zeros(shape=(len(tr_txt), len(V)), dtype=int)\n",
    "    \n",
    "    cont_doc = 0\n",
    "    for tr in tr_txt:\n",
    "        fdist_doc = nltk.FreqDist(tokenizer.tokenize(tr))\n",
    "        \n",
    "        for word, freq in fdist_doc.items():\n",
    "            if word in dict_indices:\n",
    "                BOW[cont_doc, dict_indices[word]] = freq\n",
    "        cont_doc += 1\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluamos con pesado frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 51 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       418\n",
      "           1       0.66      0.70      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.77      0.78      0.77       587\n",
      "weighted avg       0.81      0.81      0.81       587\n",
      "\n",
      "F1-score: 0.6801\n"
     ]
    }
   ],
   "source": [
    "BOW_train = frecuencia_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = frecuencia_bow(val_txt, V, dict_indices)\n",
    "svm_frecuencia = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evalúe BOW con pesado tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos BOW con esquema de peso de tf-idf\n",
    "def tfidf_bow(tr_txt, V, dict_indices):\n",
    "\n",
    "    \n",
    "    # Un BOW de frecuencia nos ayuda a obtener tf\n",
    "    # Lo haremos logaritmico\n",
    "    f_bow = frecuencia_bow(tr_txt, V, dict_indices)\n",
    "    tf = np.where(f_bow > 0, 1 + np.log10(f_bow),0)\n",
    "    \n",
    "    # De misma forma para df\n",
    "    n_docs = len(tr_txt)\n",
    "    df = np.count_nonzero(f_bow, axis=0)\n",
    "    idf = np.log10(n_docs / (1+df))\n",
    "    \n",
    "    BOW = tf*idf\n",
    "\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26137/143517032.py:8: RuntimeWarning: divide by zero encountered in log10\n",
      "  tf = np.where(f_bow > 0, 1 + np.log10(f_bow),0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  67]\n",
      " [ 57 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       418\n",
      "           1       0.63      0.66      0.64       169\n",
      "\n",
      "    accuracy                           0.79       587\n",
      "   macro avg       0.74      0.75      0.75       587\n",
      "weighted avg       0.79      0.79      0.79       587\n",
      "\n",
      "F1-score: 0.6437\n"
     ]
    }
   ],
   "source": [
    "BOW_train = tfidf_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = tfidf_bow(val_txt, V, dict_indices)\n",
    "svm_tfidf = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evalúe BOW con pesado binario normalizado l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear BOW con pesado binario normalizado l2 (norma euclidiana)\n",
    "def binarionorm_bow(tr_txt, V, dict_indices):\n",
    "    BOW = binario_bow(tr_txt, V, dict_indices)\n",
    "    norma = np.linalg.norm(BOW, axis=1, keepdims=True)\n",
    "    norma[norma==0] = 1 # Evitar div por 0\n",
    "    return BOW / norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[355  63]\n",
      " [ 50 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       418\n",
      "           1       0.65      0.70      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.77      0.78      0.77       587\n",
      "weighted avg       0.81      0.81      0.81       587\n",
      "\n",
      "F1-score: 0.6781\n"
     ]
    }
   ],
   "source": [
    "BOW_train = binarionorm_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = binarionorm_bow(val_txt, V, dict_indices)\n",
    "svm_binnorm = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evalúe BOW con pesado frecuencia normalizado l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función BOW pesado frecuencia normalizado l2\n",
    "def frecuencianorm_bow(tr_txt, V, dict_indices):\n",
    "    BOW = frecuencia_bow(tr_txt, V, dict_indices)\n",
    "    norma = np.linalg.norm(BOW, axis=1, keepdims=True)\n",
    "    norma[norma==0] = 1\n",
    "    return BOW/norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  67]\n",
      " [ 47 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       418\n",
      "           1       0.65      0.72      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.76      0.78      0.77       587\n",
      "weighted avg       0.81      0.81      0.81       587\n",
      "\n",
      "F1-score: 0.6816\n"
     ]
    }
   ],
   "source": [
    "BOW_train = frecuencianorm_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = frecuencianorm_bow(val_txt, V, dict_indices)\n",
    "svm_frecnorm = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evalúe BOW con pesado tfidf normalizado l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidfnorm_bow(tr_txt, V, dict_indices):\n",
    "    BOW = tfidf_bow(tr_txt, V, dict_indices)\n",
    "    norma = np.linalg.norm(BOW, axis=1, keepdims=True)\n",
    "    norma[norma==0] = 1\n",
    "    return BOW/norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26137/143517032.py:8: RuntimeWarning: divide by zero encountered in log10\n",
      "  tf = np.where(f_bow > 0, 1 + np.log10(f_bow),0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 50 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       418\n",
      "           1       0.66      0.70      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.77      0.78      0.78       587\n",
      "weighted avg       0.82      0.81      0.81       587\n",
      "\n",
      "F1-score: 0.6839\n"
     ]
    }
   ],
   "source": [
    "BOW_train = tfidfnorm_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = tfidfnorm_bow(val_txt, V, dict_indices)\n",
    "svm_tfidfnorm = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ponga una tabla comparativa a modo de resumen con las seis entradas anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representación  | Macro F1\n",
    "----------------|----------\n",
    "Binario         | **69.39%**\n",
    "Frecuencia      | 68.01%\n",
    "TF-IDF          | 64.37%\n",
    "Binario L2      | 67.81%\n",
    "Frecuencia L2   | 68.16%\n",
    "TF-IDF L2       | 68.39%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. De las configuraciones anteriores eliga la mejor y evalúela con más y menos términos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todo el vocabulario con al menos dos ocurrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 4281\n",
      "Tamaño del diccionario: 4281\n"
     ]
    }
   ],
   "source": [
    "V = [(fdist[key], key) for key in fdist if fdist[key] > 1]\n",
    "V.sort()\n",
    "V.reverse()\n",
    "longitud_vocabulario = len(V)\n",
    "print(f\"Tamaño del vocabulario: {longitud_vocabulario}\")\n",
    "\n",
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for freq, word in V:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1\n",
    "print(f\"Tamaño del diccionario: {len(dict_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[363  55]\n",
      " [ 50 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       418\n",
      "           1       0.68      0.70      0.69       169\n",
      "\n",
      "    accuracy                           0.82       587\n",
      "   macro avg       0.78      0.79      0.78       587\n",
      "weighted avg       0.82      0.82      0.82       587\n",
      "\n",
      "F1-score: 0.6939\n"
     ]
    }
   ],
   "source": [
    "BOW_train = binario_bow(tr_txt, V, dict_indices)\n",
    "BOW_test = binario_bow(val_txt, V, dict_indices)\n",
    "svm_masPalabras = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mitad del Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 2140\n",
      "Tamaño del diccionario: 2140\n"
     ]
    }
   ],
   "source": [
    "V_dosTercios = V[:int(longitud_vocabulario/2)]\n",
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for freq, word in V_dosTercios:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1\n",
    "print(f\"Tamaño del vocabulario: {len(V_dosTercios)}\")\n",
    "print(f\"Tamaño del diccionario: {len(dict_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[360  58]\n",
      " [ 47 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       418\n",
      "           1       0.68      0.72      0.70       169\n",
      "\n",
      "    accuracy                           0.82       587\n",
      "   macro avg       0.78      0.79      0.79       587\n",
      "weighted avg       0.82      0.82      0.82       587\n",
      "\n",
      "F1-score: 0.6991\n"
     ]
    }
   ],
   "source": [
    "BOW_train = binario_bow(tr_txt, V_dosTercios, dict_indices)\n",
    "BOW_test = binario_bow(val_txt, V_dosTercios, dict_indices)\n",
    "svm_mitadPalabras = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 1000\n",
      "Tamaño del diccionario: 1000\n"
     ]
    }
   ],
   "source": [
    "V_1000 = V[:1000]\n",
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for freq, word in V_1000:\n",
    "    dict_indices[word] = cont\n",
    "    cont += 1\n",
    "print(f\"Tamaño del vocabulario: {len(V_1000)}\")\n",
    "print(f\"Tamaño del diccionario: {len(dict_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [ 51 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       418\n",
      "           1       0.66      0.70      0.68       169\n",
      "\n",
      "    accuracy                           0.81       587\n",
      "   macro avg       0.77      0.78      0.77       587\n",
      "weighted avg       0.81      0.81      0.81       587\n",
      "\n",
      "F1-score: 0.6801\n"
     ]
    }
   ],
   "source": [
    "BOW_train = binario_bow(tr_txt, V_dosTercios, dict_indices)\n",
    "BOW_test = binario_bow(val_txt, V_dosTercios, dict_indices)\n",
    "svm_1000 = evaluar_bow(BOW_train,BOW_test, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurso Léxico EmoLex para construir una Bolsa de Emociones (BoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_path = \"./data/Spanish-NRC-EmoLex.txt\"\n",
    "emolex = pd.read_csv(emolex_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El recurso que encontré se encuentra en `./data/Spanish-NRC-EmoLex.txt`. Inspeccionandolo encuentro que:\n",
    "* Cada renglón es una palabra, al que le corresponde un *vector de emociones* incluyendo el sentimiento **positivo** o **negativo**.\n",
    "* Las palabras provienen del inglés y son traducidas al español, por lo que puede haber palabras repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "English Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "anger",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "anticipation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "disgust",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "joy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "negative",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "positive",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sadness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "surprise",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trust",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Spanish Word",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2888e69f-d89e-4e78-9e03-f8e5e9ee4ee0",
       "rows": [
        [
         "0",
         "aback",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "detrás"
        ],
        [
         "1",
         "abacus",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "ábaco"
        ],
        [
         "2",
         "abandon",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "abandonar"
        ],
        [
         "3",
         "abandoned",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "abandonado"
        ],
        [
         "4",
         "abandonment",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "abandono"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English Word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>Spanish Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>detrás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ábaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abandonar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abandonado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abandono</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English Word  anger  anticipation  disgust  fear  joy  negative  positive  \\\n",
       "0        aback      0             0        0     0    0         0         0   \n",
       "1       abacus      0             0        0     0    0         0         0   \n",
       "2      abandon      0             0        0     1    0         1         0   \n",
       "3    abandoned      1             0        0     1    0         1         0   \n",
       "4  abandonment      1             0        0     1    0         1         0   \n",
       "\n",
       "   sadness  surprise  trust Spanish Word  \n",
       "0        0         0      0       detrás  \n",
       "1        0         0      1        ábaco  \n",
       "2        1         0      0    abandonar  \n",
       "3        1         0      0   abandonado  \n",
       "4        1         1      0     abandono  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitaré las dimensiones `positivo`, `negativo` y `English Word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "anger",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "anticipation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "disgust",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "joy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sadness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "surprise",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trust",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Spanish Word",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c79634f3-5311-4e8b-968d-8e0d4dd6e02c",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "detrás"
        ],
        [
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "ábaco"
        ],
        [
         "2",
         "0",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "abandonar"
        ],
        [
         "3",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "abandonado"
        ],
        [
         "4",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "abandono"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>Spanish Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>detrás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ábaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abandonar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abandonado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abandono</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  sadness  surprise  trust  \\\n",
       "0      0             0        0     0    0        0         0      0   \n",
       "1      0             0        0     0    0        0         0      1   \n",
       "2      0             0        0     1    0        1         0      0   \n",
       "3      1             0        0     1    0        1         0      0   \n",
       "4      1             0        0     1    0        1         1      0   \n",
       "\n",
       "  Spanish Word  \n",
       "0       detrás  \n",
       "1        ábaco  \n",
       "2    abandonar  \n",
       "3   abandonado  \n",
       "4     abandono  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_emolex = emolex.drop(columns=[\"English Word\", \"positive\", \"negative\"])\n",
    "clean_emolex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo la propuesta de enmascarar cada término con su emoción, pienso representar cada tweet mediante la suma de emociones de sus términos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetAVector(tweet : str, emolex : pd.DataFrame):\n",
    "    vector = np.zeros(8)\n",
    "    palabras = tokenizer.tokenize(tweet.lower())\n",
    "    \n",
    "    # Obtener solo palabras en el lexicon\n",
    "    ocurrencias = emolex[emolex[\"Spanish Word\"].isin(palabras)]\n",
    "    \n",
    "    if not ocurrencias.empty:\n",
    "        vector = ocurrencias.drop(columns=\"Spanish Word\").sum(axis=0).to_numpy()\n",
    "    \n",
    "    return vector\n",
    "    #return vector / np.linalg.norm(vector) if np.linalg.norm(vector) != 0 else vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearBoE(tr_txt, emolex):\n",
    "    BoE = np.zeros(shape=(len(tr_txt), 8))\n",
    "    \n",
    "    for i, tweet in enumerate(tr_txt):\n",
    "        BoE[i] = tweetAVector(tweet, emolex)\n",
    "        \n",
    "    return BoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_emotions_train = crearBoE(tr_txt, clean_emolex)\n",
    "bag_of_emotions_test = crearBoE(val_txt, clean_emolex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gus/anaconda3/envs/tf_env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[358  60]\n",
      " [123  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       418\n",
      "           1       0.43      0.27      0.33       169\n",
      "\n",
      "    accuracy                           0.69       587\n",
      "   macro avg       0.59      0.56      0.57       587\n",
      "weighted avg       0.65      0.69      0.66       587\n",
      "\n",
      "F1-score: 0.3345\n"
     ]
    }
   ],
   "source": [
    "svm_emolex = evaluar_bow(bag_of_emotions_train, bag_of_emotions_test, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
